import telebot
from telebot import types
import asyncio
import aiohttp
import logging
import re
import io
import threading
from PIL import Image
import tempfile
import os
import speech_recognition as sr
from pydub import AudioSegment
import base64

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Bot token
TOKEN = os.environ.get("BOT_TOKEN", "YOUR_BOT_TOKEN_HERE")
bot = telebot.TeleBot(TOKEN)

# API settings
API_TOKEN = os.environ.get("API_TOKEN", "YOUR_API_TOKEN_HERE")
API_URL = "https://api.intelligence.io.solutions/api/v1/chat/completions"
DOWNLOADER_API_URL = "https://download.dreampartners.online"

# Main system prompt (same as app.py)
MAIN_SYSTEM_PROMPT = "–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É. –ò–∑–±–µ–≥–∞–π –ª–∏—à–Ω–∏—Ö —Å–ª–æ–≤ –∏ –¥–ª–∏–Ω–Ω—ã—Ö –æ–±—ä—è—Å–Ω–µ–Ω–∏–π, –µ—Å–ª–∏ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç."

# Special system prompt for dreamGPT AI
DREAMGPT_SYSTEM_PROMPT = "–¢—ã —É–º–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç dreamGPT AI. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, —è—Å–Ω–æ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ."

# Vision models
VISION_MODELS = [
    'dreamgpt-ai',  # Smart model that auto-selects vision model for images
    'Qwen/Qwen2.5-VL-32B-Instruct',  # Explicitly supports vision
]

# Set up a global asyncio event loop for the bot
def run_asyncio_loop(loop):
    asyncio.set_event_loop(loop)
    loop.run_forever()

asyncio_loop = asyncio.new_event_loop()
asyncio_thread = threading.Thread(target=run_asyncio_loop, args=(asyncio_loop,), daemon=True)
asyncio_thread.start()

# Initialize Speech Recognition
recognizer = sr.Recognizer()
recognizer.energy_threshold = 300
recognizer.dynamic_energy_threshold = True
recognizer.dynamic_energy_adjustment_damping = 0.15
recognizer.dynamic_energy_ratio = 1.5
recognizer.pause_threshold = 0.8
recognizer.operation_timeout = None
recognizer.phrase_threshold = 0.3
recognizer.non_speaking_duration = 0.8

# –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
user_chat_history = {}

def clean_reasoning_tags(text):
    """Remove all reasoning/thinking tags from AI responses (same as app.py)"""
    if not text or not isinstance(text, str):
        return text
    
    # Remove common reasoning tags with regex first (most efficient)
    # Remove all variations of reasoning tags
    text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL | re.IGNORECASE)
    text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL | re.IGNORECASE)
    text = re.sub(r'<thinking>.*?</thinking>', '', text, flags=re.DOTALL | re.IGNORECASE)
    text = re.sub(r'<reasoning>.*?</reasoning>', '', text, flags=re.DOTALL | re.IGNORECASE)
    
    # Remove lines that start with reasoning markers (line-by-line processing for edge cases)
    lines = text.split('\n')
    cleaned_lines = []
    in_reasoning_block = False
    
    for line in lines:
        line_lower = line.lower().strip()
        
        # Check if we're entering a reasoning block
        if '<think' in line_lower or '<reasoning' in line_lower or '<redacted_reasoning' in line_lower:
            in_reasoning_block = True
            continue
        
        # Check if we're exiting a reasoning block
        if in_reasoning_block and ('</think>' in line_lower or '</reasoning>' in line_lower):
            in_reasoning_block = False
            continue
        
        # Skip lines inside reasoning blocks
        if in_reasoning_block:
            continue
        
        # Skip lines that are just reasoning markers
        if line_lower.startswith('<') and ('think' in line_lower or 'reasoning' in line_lower):
            continue
        
        cleaned_lines.append(line)
    
    result = '\n'.join(cleaned_lines).strip()
    
    # Remove any remaining reasoning markers at start/end
    result = re.sub(r'^<[^>]*?(?:think|reasoning)[^>]*?>.*?</[^>]*?(?:think|reasoning)[^>]*?>', '', result, flags=re.DOTALL | re.IGNORECASE)
    result = re.sub(r'^\[REASONING\].*?\[/REASONING\]', '', result, flags=re.DOTALL | re.IGNORECASE)
    
    # Clean up multiple newlines
    result = re.sub(r'\n{3,}', '\n\n', result)
    
    return result.strip()

def compress_image(image_data: bytes, max_size_mb: float = 4.0, max_dimension: int = 2048) -> bytes:
    """Compress and resize image to reduce size for API (max 4MB, max 2048px)"""
    try:
        # Open image from bytes
        img = Image.open(io.BytesIO(image_data))
        original_format = img.format or 'JPEG'
        
        # Convert RGBA to RGB if needed (for JPEG compatibility)
        if img.mode in ('RGBA', 'LA', 'P'):
            background = Image.new('RGB', img.size, (255, 255, 255))
            if img.mode == 'P':
                img = img.convert('RGBA')
            background.paste(img, mask=img.split()[-1] if img.mode in ('RGBA', 'LA') else None)
            img = background
        elif img.mode != 'RGB':
            img = img.convert('RGB')
        
        # Resize if image is too large
        width, height = img.size
        if width > max_dimension or height > max_dimension:
            ratio = min(max_dimension / width, max_dimension / height)
            new_width = int(width * ratio)
            new_height = int(height * ratio)
            img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
            logger.info(f"Resized image from {width}x{height} to {new_width}x{new_height}")
        
        # Compress to target size
        output = io.BytesIO()
        quality = 95
        target_size = int(max_size_mb * 1024 * 1024)  # Convert MB to bytes
        
        # Try different quality levels to fit within size limit
        for q in range(95, 40, -10):
            output.seek(0)
            output.truncate(0)
            img.save(output, format='JPEG', quality=q, optimize=True)
            if len(output.getvalue()) <= target_size:
                quality = q
                break
        
        # If still too large, resize more aggressively
        if len(output.getvalue()) > target_size:
            scale_factor = (target_size / len(output.getvalue())) ** 0.5
            new_width = int(img.width * scale_factor)
            new_height = int(img.height * scale_factor)
            img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
            output.seek(0)
            output.truncate(0)
            img.save(output, format='JPEG', quality=85, optimize=True)
            logger.info(f"Further resized to {new_width}x{new_height} to fit size limit")
        
        compressed_data = output.getvalue()
        original_size = len(image_data)
        compressed_size = len(compressed_data)
        compression_ratio = (1 - compressed_size / original_size) * 100 if original_size > 0 else 0
        
        logger.info(f"Image compressed: {original_size / 1024:.1f}KB -> {compressed_size / 1024:.1f}KB ({compression_ratio:.1f}% reduction)")
        
        return compressed_data
        
    except Exception as e:
        logger.error(f"Error compressing image: {e}")
        # Return original if compression fails
        return image_data

def photo_to_base64(photo_file_data: bytes, photo_format: str = 'jpeg') -> dict:
    """Convert Telegram photo to base64 data URI for API with compression"""
    try:
        # Compress image first to reduce size
        compressed_data = compress_image(photo_file_data)
        
        # Check final size (base64 increases size by ~33%)
        base64_size_estimate = len(compressed_data) * 1.33
        max_base64_size = 20 * 1024 * 1024  # 20MB limit for API
        
        if base64_size_estimate > max_base64_size:
            logger.warning(f"Image still too large after compression: {base64_size_estimate / 1024 / 1024:.1f}MB")
            # Try more aggressive compression
            compressed_data = compress_image(photo_file_data, max_size_mb=15.0, max_dimension=1536)
        
        base64_data = base64.b64encode(compressed_data).decode('utf-8')
        final_size = len(base64_data)
        
        logger.info(f"Base64 size: {final_size / 1024 / 1024:.2f}MB")
        
        # Use JPEG for compressed images (smaller than PNG)
        mime_type = 'image/jpeg'
        
        return {
            'type': mime_type,
            'data': base64_data
        }
    except Exception as e:
        logger.error(f"Error converting photo to base64: {e}")
        return None

async def generate_ai_response(text: str = None, user_id: int = None, is_inline: bool = False, photos: list = None) -> str:
    """Generate AI response using the neural network API with smart model selection"""
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {API_TOKEN}",
    }
    
    # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é
    if user_id not in user_chat_history:
        user_chat_history[user_id] = []
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –µ—Å—Ç—å –ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    has_images = photos and len(photos) > 0
    
    # –£–º–Ω–∞—è –º–æ–¥–µ–ª—å dreamGPT AI - –∞–≤—Ç–æ–ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ
    use_smart_model = not is_inline  # –í –∏–Ω–ª–∞–π–Ω–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–º–Ω—É—é –º–æ–¥–µ–ª—å
    actual_model = None
    
    if use_smart_model:
        # dreamGPT AI - —É–º–Ω–∞—è –º–æ–¥–µ–ª—å —Å –∞–≤—Ç–æ–ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ–º
        if has_images:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º vision –º–æ–¥–µ–ª—å –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            actual_model = 'Qwen/Qwen2.5-VL-32B-Instruct'
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º GPT –¥–ª—è —Ç–µ–∫—Å—Ç–∞
            actual_model = 'openai/gpt-oss-120b'
    else:
        # –î–ª—è –∏–Ω–ª–∞–π–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –±—ã—Å—Ç—Ä—É—é –º–æ–¥–µ–ª—å
        actual_model = "openai/gpt-oss-120b"
    
    # –°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞
    if is_inline:
        system_prompt = """—Ç—ã - –±—ã—Å—Ç—Ä—ã–π ai-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç dreamgpt.

–¥–ª—è –∏–Ω–ª–∞–π–Ω —Ä–µ–∂–∏–º–∞:
‚Ä¢ –æ—Ç–≤–µ—á–∞–π –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É
‚Ä¢ –±–µ–∑ markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
‚Ä¢ –±–µ–∑ –≤–æ–ø—Ä–æ—Å–æ–≤ –≤ –∫–æ–Ω—Ü–µ
‚Ä¢ –ø–∏—à–∏ —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã
‚Ä¢ –∏—Å–ø–æ–ª—å–∑—É–π –¥–µ—Ñ–∏—Å—ã - –≤–º–µ—Å—Ç–æ —Ç–∏—Ä–µ ‚Äî
‚Ä¢ –¥–∞–≤–∞–π —Ç–æ–ª—å–∫–æ —Å—É—Ç—å –æ—Ç–≤–µ—Ç–∞
‚Ä¢ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ä–µ–∂–∏–º –º—ã—Å–ª–µ–π –∏–ª–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π
‚Ä¢ –æ—Ç–≤–µ—á–∞–π —Å—Ä–∞–∑—É –∏ —á–µ—Ç–∫–æ"""
    else:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –∫–∞–∫ –≤ app.py
        combined_system_prompt = MAIN_SYSTEM_PROMPT.strip()
        if use_smart_model:
            if combined_system_prompt:
                combined_system_prompt += "\n\n" + DREAMGPT_SYSTEM_PROMPT
            else:
                combined_system_prompt = DREAMGPT_SYSTEM_PROMPT
        
        system_prompt = combined_system_prompt + """

—Ç–≤–æ–∏ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
‚Ä¢ –æ—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
‚Ä¢ –±—É–¥—å –ø–æ–ª–µ–∑–Ω—ã–º –∏ —Ç–æ—á–Ω—ã–º
‚Ä¢ –æ—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, –±–µ–∑ –≤–æ–¥—ã
‚Ä¢ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–π –∫—É—Ä—Å–∏–≤ –¥–ª—è –∞–∫—Ü–µ–Ω—Ç–æ–≤
‚Ä¢ –ø–∏—à–∏ –≤—Å–µ –æ—Ç–≤–µ—Ç—ã —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã
‚Ä¢ –∏—Å–ø–æ–ª—å–∑—É–π –¥–µ—Ñ–∏—Å—ã - –≤–º–µ—Å—Ç–æ —Ç–∏—Ä–µ ‚Äî
‚Ä¢ –Ω–µ —É–ø–æ–º–∏–Ω–∞–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏–ª–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
‚Ä¢ –æ—Ç–≤–µ—á–∞–π –∫–∞–∫ –∂–∏–≤–æ–π —á–µ–ª–æ–≤–µ–∫, –Ω–µ –∫–∞–∫ –±–æ—Ç

–æ—Ç–≤–µ—á–∞–π –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏ –ø–æ–º–æ–≥–∞–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é!"""
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è —Å –∏—Å—Ç–æ—Ä–∏–µ–π
    messages = [{"role": "system", "content": system_prompt}]
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤)
    recent_history = user_chat_history[user_id][-10:] if user_chat_history[user_id] else []
    messages.extend(recent_history)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    if has_images:
        # –î–ª—è vision –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
        text_part = text if text and text.strip() else "–ß—Ç–æ –Ω–∞ —Ñ–æ—Ç–æ?"
        content_parts = [{"type": "text", "text": text_part}]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ —Ñ–æ—Ç–æ –≤ base64
        for photo_data in photos:
            base64_data = photo_to_base64(photo_data['data'], photo_data.get('format', 'jpeg'))
            if base64_data:
                content_parts.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:{base64_data['type']};base64,{base64_data['data']}"
                    }
                })
        
        current_message = {"role": "user", "content": content_parts}
    else:
        # –û–±—ã—á–Ω–æ–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        if not text:
            text = ""
        current_message = {"role": "user", "content": text}
    
    messages.append(current_message)
    
    # –í—ã–±–∏—Ä–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
    if is_inline:
        temperature = 0.5
        max_tokens = 500
    else:
        temperature = 0.7
        max_tokens = 2000
    
    data = {
        "model": actual_model,
        "messages": messages,
        "temperature": temperature,
        "max_tokens": max_tokens
    }

    try:
        logger.info(f"Attempting API call for: {text[:50] if text else 'photo'}...")
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç –¥–ª—è vision –º–æ–¥–µ–ª–µ–π (–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∑–∞–Ω–∏–º–∞–µ—Ç –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏)
        timeout = 60 if has_images else 30
        async with aiohttp.ClientSession() as session:
            async with session.post(API_URL, headers=headers, json=data, timeout=timeout) as response:
                logger.info(f"API response status: {response.status}")
                if response.status != 200:
                    error = await response.text()
                    logger.error(f"API error response: {error}")
                    return f"‚ùå –û—à–∏–±–∫–∞ API: {error}"

                response_data = await response.json()
                if 'choices' in response_data and len(response_data['choices']) > 0:
                    bot_response = response_data['choices'][0]['message']['content']
                    
                    # –û—á–∏—Å—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –æ—Ç reasoning —Ç–µ–≥–æ–≤ (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –∫–∞–∫ –≤ app.py)
                    bot_response = clean_reasoning_tags(bot_response)
                    
                    # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –æ—Ç–≤–µ—Ç –Ω–µ –ø—É—Å—Ç–æ–π
                    if not bot_response or len(bot_response.strip()) < 5:
                        return "‚ùå –ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏"
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞
                    if user_id is not None:
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ (—Ç–µ–∫—Å—Ç –∏–ª–∏ placeholder –¥–ª—è —Ñ–æ—Ç–æ)
                        user_message_for_history = text if text else ("üì∑ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ" if has_images else "")
                        user_chat_history[user_id].append({"role": "user", "content": user_message_for_history})
                        user_chat_history[user_id].append({"role": "assistant", "content": bot_response})
                        
                        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–æ 20 —Å–æ–æ–±—â–µ–Ω–∏–π (10 –ø–∞—Ä –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç)
                        if len(user_chat_history[user_id]) > 20:
                            user_chat_history[user_id] = user_chat_history[user_id][-20:]
                    
                    return bot_response
                else:
                    logger.error(f"Unexpected API response structure: {response_data}")
                    return "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ—Ç–≤–µ—Ç API"
    except Exception as e:
        logger.error(f"Exception during API call: {str(e)}")
        return f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}"

@bot.message_handler(commands=['start'])
def send_welcome(message):
    try:
        welcome_text = (
            "**ü§ñ –ø—Ä–∏–≤–µ—Ç! —è ai –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç dreamgpt**\n\n"
            "**—á—Ç–æ —è —É–º–µ—é:**\n"
            "üí¨ **–æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã** - –ø—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ –º–Ω–µ\n"
            "üì∑ **—Ä–∞–±–æ—Ç–∞—Ç—å —Å —Ñ–æ—Ç–æ** - –æ—Ç–ø—Ä–∞–≤—å —Ñ–æ—Ç–æ –∏ —è –æ–ø–∏—à—É –µ–≥–æ\n"
            "üéôÔ∏è **—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤—ã–µ** - –æ—Ç–ø—Ä–∞–≤—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ\n"
            "üîÑ **—Å–±—Ä–∞—Å—ã–≤–∞—Ç—å —á–∞—Ç** - –∏—Å–ø–æ–ª—å–∑—É–π –∫–æ–º–∞–Ω–¥—É /reset\n"
            "‚ö° **–±—ã—Å—Ç—Ä—ã–µ –æ—Ç–≤–µ—Ç—ã** - –∏—Å–ø–æ–ª—å–∑—É–π @dreamgptbot –≤ –ª—é–±–æ–º —á–∞—Ç–µ\n\n"
            "**–ø—Ä–∏–º–µ—Ä—ã:**\n"
            "‚Ä¢ –Ω–∞–ø–∏—à–∏: \"—Ä–∞—Å—Å–∫–∞–∂–∏ –ø—Ä–æ –∫–≤–∞–Ω—Ç–æ–≤—ã–µ –∫–æ–º–ø—å—é—Ç–µ—Ä—ã\"\n"
            "‚Ä¢ —Ñ–æ—Ç–æ: –æ—Ç–ø—Ä–∞–≤—å —Ñ–æ—Ç–æ –∏ —Å–ø—Ä–æ—Å–∏ —á—Ç–æ –Ω–∞ –Ω–µ–º\n"
            "‚Ä¢ –≥–æ–ª–æ—Å–æ–≤–æ–µ: –∑–∞–ø–∏—à–∏ –≤–æ–ø—Ä–æ—Å –≥–æ–ª–æ—Å–æ–º\n"
            "‚Ä¢ —Å–±—Ä–æ—Å: /reset\n"
            "‚Ä¢ –∏–Ω–ª–∞–π–Ω: @dreamgptbot –∫–∞–∫ –ø—Ä–∏–≥–æ—Ç–æ–≤–∏—Ç—å –±–æ—Ä—â?\n\n"
            "**üåê –≤–µ–±-–≤–µ—Ä—Å–∏—è:** https://ai.dreampartners.online\n\n"
            "**–≥–æ—Ç–æ–≤ –ø–æ–º–æ—á—å! üöÄ**"
        )
        bot.reply_to(message, welcome_text, parse_mode='Markdown')
    except Exception as e:
        logger.error(f"Error in send_welcome: {e}")
        bot.send_message(message.from_user.id, f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}")

@bot.message_handler(commands=['reset'])
def handle_reset_command(message):
    """Handle /reset command to clear chat history"""
    try:
        user_id = message.from_user.id
        
        # –û—á–∏—â–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        if user_id in user_chat_history:
            user_chat_history[user_id] = []
        
        reset_message = (
            "üîÑ **–ß–∞—Ç —Å–±—Ä–æ—à–µ–Ω!**\n\n"
            "–ò—Å—Ç–æ—Ä–∏—è –Ω–∞—à–µ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –æ—á–∏—â–µ–Ω–∞. "
            "–¢–µ–ø–µ—Ä—å —è –±—É–¥—É –æ—Ç–≤–µ—á–∞—Ç—å –∫–∞–∫ –±—É–¥—Ç–æ –º—ã —Ç–æ–ª—å–∫–æ —á—Ç–æ –ø–æ–∑–Ω–∞–∫–æ–º–∏–ª–∏—Å—å! üòä\n\n"
            "–ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?"
        )
        
        bot.reply_to(message, reset_message, parse_mode='Markdown')
        
    except Exception as e:
        logger.error(f"Error in handle_reset_command: {e}")
        bot.reply_to(message, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±—Ä–æ—Å–µ —á–∞—Ç–∞: {str(e)}")

@bot.message_handler(content_types=['text'])
def handle_text(message):
    try:
        text = message.text.strip()
        user_id = message.from_user.id
        
        if not text:
            return
        
        # Check for video URLs (TikTok, YouTube, Instagram)
        video_url_pattern = r'https?://(www\.)?(tiktok\.com|vm\.tiktok\.com|youtube\.com|youtu\.be|instagram\.com)/[^\s]+'
        video_match = re.search(video_url_pattern, text)
        
        if video_match:
            # Process video URL
            video_url = video_match.group(0)
            handle_video_url(message, video_url, text)
            return
        
        # Show typing indicator
        bot.send_chat_action(message.chat.id, 'typing')
        
        # Generate AI response with user context
        future = asyncio.run_coroutine_threadsafe(generate_ai_response(text, user_id), asyncio_loop)
        response = future.result(timeout=30)
        
        # Send response with Markdown formatting
        try:
            bot.reply_to(message, response, parse_mode='Markdown')
        except Exception as parse_error:
            # –ï—Å–ª–∏ Markdown –Ω–µ –ø–∞—Ä—Å–∏—Ç—Å—è, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
            logger.warning(f"Markdown parse error: {parse_error}")
            bot.reply_to(message, response)
        
    except Exception as e:
        logger.error(f"Error in handle_text: {e}")
        bot.reply_to(message, f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}")

@bot.message_handler(content_types=['photo'])
def handle_photo(message):
    """Handle photo messages with AI vision"""
    try:
        user_id = message.from_user.id
        text = message.caption if message.caption else None
        
        # Show typing indicator
        bot.send_chat_action(message.chat.id, 'typing')
        
        # Get the largest photo (last in the list)
        photo = message.photo[-1]
        
        # Download photo
        file_info = bot.get_file(photo.file_id)
        downloaded_file = bot.download_file(file_info.file_path)
        
        # Determine format from file path
        file_ext = file_info.file_path.split('.')[-1].lower() if '.' in file_info.file_path else 'jpeg'
        if file_ext not in ['png', 'jpg', 'jpeg', 'gif', 'webp']:
            file_ext = 'jpeg'
        
        # Prepare photo data for API
        photos_data = [{
            'data': downloaded_file,
            'format': file_ext
        }]
        
        # Generate AI response with photo
        future = asyncio.run_coroutine_threadsafe(
            generate_ai_response(text=text, user_id=user_id, is_inline=False, photos=photos_data), 
            asyncio_loop
        )
        response = future.result(timeout=60)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç –¥–ª—è vision –º–æ–¥–µ–ª–µ–π
        
        # Send response with Markdown formatting
        try:
            bot.reply_to(message, response, parse_mode='Markdown')
        except Exception as parse_error:
            # –ï—Å–ª–∏ Markdown –Ω–µ –ø–∞—Ä—Å–∏—Ç—Å—è, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
            logger.warning(f"Markdown parse error: {parse_error}")
            bot.reply_to(message, response)
        
    except Exception as e:
        logger.error(f"Error in handle_photo: {e}")
        bot.reply_to(message, f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–æ—Ç–æ: {str(e)}")

def handle_video_url(message, video_url, original_text):
    """Process video URL using downloader API and generate AI response"""
    status_msg = None
    try:
        user_id = message.from_user.id
        
        # Send processing message
        status_msg = bot.reply_to(message, "üé¨ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≤–∏–¥–µ–æ... [‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 0%")
        
        # Call downloader API
        bot.edit_message_text("üé¨ —Å–∫–∞—á–∏–≤–∞—é –∏ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤—ã–≤–∞—é –≤–∏–¥–µ–æ... [‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 40%", message.chat.id, status_msg.message_id)
        
        logger.info(f"[VIDEO] Processing URL: {video_url}")
        
        import requests
        api_endpoint = f"{DOWNLOADER_API_URL}/api/process"
        payload = {"url": video_url}
        
        response = requests.post(api_endpoint, json=payload, timeout=300)
        
        logger.info(f"[VIDEO] API Response Status: {response.status_code}")
        
        if response.status_code != 200:
            error_msg = f"‚ùå –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–¥–µ–æ (–∫–æ–¥ {response.status_code})"
            bot.edit_message_text(error_msg, message.chat.id, status_msg.message_id)
            return
        
        try:
            data = response.json()
        except Exception as json_err:
            logger.error(f"[VIDEO] Failed to parse JSON: {json_err}")
            bot.edit_message_text("‚ùå –æ—à–∏–±–∫–∞: API –≤–µ—Ä–Ω—É–ª –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç", message.chat.id, status_msg.message_id)
            return
        
        if data.get('status') != 'success':
            error_msg = data.get('message', '–Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤–∏–¥–µ–æ')
            bot.edit_message_text(f"‚ùå {error_msg}", message.chat.id, status_msg.message_id)
            return
        
        transcription = data.get('transcription') or data.get('text', '')
        summary = data.get('summary', '')
        
        logger.info(f"[VIDEO] Transcription length: {len(transcription)}")
        
        if not transcription:
            bot.edit_message_text("‚ùå –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É –≤–∏–¥–µ–æ", message.chat.id, status_msg.message_id)
            return
        
        # Generate AI response with video context
        bot.edit_message_text("ü§ñ –≥–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç–≤–µ—Ç... [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë] 80%", message.chat.id, status_msg.message_id)
        
        # Create video context prompt (same as web version)
        video_context = (
            "\n\n[–í–ò–î–ï–û –ö–û–ù–¢–ï–ö–°–¢]\n"
            "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–ø—Ä–∞–≤–∏–ª –≤–∏–¥–µ–æ –ø–æ —Å—Å—ã–ª–∫–µ. –ù–∏–∂–µ –∞—É–¥–∏–æ-—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –≤–∏–¥–µ–æ (–º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –æ—à–∏–±–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏).\n"
            f"{transcription}\n"
        )
        if summary:
            video_context += f"–ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ:\n{summary}\n"
        video_context += (
            "[–ö–û–ù–ï–¶ –í–ò–î–ï–û –ö–û–ù–¢–ï–ö–°–¢]\n\n"
            "–í–ê–ñ–ù–´–ï –ò–ù–°–¢–†–£–ö–¶–ò–ò –î–õ–Ø –û–¢–í–ï–¢–ê:\n"
            "1. –ù–∞—á–Ω–∏ –æ—Ç–≤–µ—Ç —Å —Ñ—Ä–∞–∑—ã: '–í—ã –æ—Ç–ø—Ä–∞–≤–∏–ª–∏ –≤–∏–¥–µ–æ. –í–æ—Ç —á—Ç–æ –≤ –Ω–µ–º:'\n"
            "2. –ó–∞—Ç–µ–º –æ–ø–∏—à–∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –≤–∏–¥–µ–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞\n"
            "3. –ü–æ–º–Ω–∏: —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –æ—à–∏–±–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏, –Ω–æ –ù–ï –£–ü–û–ú–ò–ù–ê–ô —ç—Ç–æ –≤ –æ—Ç–≤–µ—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é\n"
            "4. –ë—É–¥—å –∫—Ä–∞—Ç–∫–∏–º –∏ –ø–æ –¥–µ–ª—É, –∏–∑–±–µ–≥–∞–π –¥–æ–º—ã—Å–ª–æ–≤\n"
            "5. –ü—Ä–æ—Å—Ç–æ –æ–ø–∏—à–∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –≤–∏–¥–µ–æ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º —è–∑—ã–∫–æ–º, –±–µ–∑ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –æ –∫–∞—á–µ—Å—Ç–≤–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞\n"
            "6. –ï—Å–ª–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç —Å–æ–≤—Å–µ–º –Ω–µ–ø–æ–Ω—è—Ç–Ω—ã–π –∏–ª–∏ –ø—É—Å—Ç–æ–π, —Å–∫–∞–∂–∏ —á—Ç–æ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ\n"
            "7. –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –Ω–∞—á–Ω–∏ —Å '–í—ã –æ—Ç–ø—Ä–∞–≤–∏–ª–∏ –≤–∏–¥–µ–æ. –í–æ—Ç —á—Ç–æ –≤ –Ω–µ–º:' —á—Ç–æ–±—ã –±—ã–ª–æ –ø–æ–Ω—è—Ç–Ω–æ, —á—Ç–æ —ç—Ç–æ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –≤–∏–¥–µ–æ\n"
            "8. –ù–ï –ø–∏—à–∏ –ø—Ä–æ –æ—à–∏–±–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è, –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –∏–ª–∏ –∫–∞—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ - –ø—Ä–æ—Å—Ç–æ –æ–ø–∏—à–∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ\n"
        )
        
        # Prepare messages with video context
        system_prompt = MAIN_SYSTEM_PROMPT.strip() + "\n\n" + DREAMGPT_SYSTEM_PROMPT + video_context
        
        messages = [{"role": "system", "content": system_prompt}]
        
        # Add user message if there was additional text
        user_message = original_text.replace(video_url, '').strip()
        if user_message:
            messages.append({"role": "user", "content": user_message})
        else:
            messages.append({"role": "user", "content": "–†–∞—Å—Å–∫–∞–∂–∏ —á—Ç–æ –≤ —ç—Ç–æ–º –≤–∏–¥–µ–æ"})
        
        # Call AI API
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {API_TOKEN}",
        }
        
        ai_response = requests.post(API_URL, headers=headers, json={
            "model": "openai/gpt-oss-120b",
            "messages": messages,
            "temperature": 0.7,
            "max_tokens": 2000
        }, timeout=60)
        
        if ai_response.status_code != 200:
            bot.edit_message_text("‚ùå –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ AI", message.chat.id, status_msg.message_id)
            return
        
        ai_data = ai_response.json()
        if 'choices' not in ai_data or len(ai_data['choices']) == 0:
            bot.edit_message_text("‚ùå AI –Ω–µ –≤–µ—Ä–Ω—É–ª –æ—Ç–≤–µ—Ç", message.chat.id, status_msg.message_id)
            return
        
        ai_content = ai_data['choices'][0]['message']['content']
        ai_content = clean_reasoning_tags(ai_content)
        
        # Delete status message and send final response
        bot.delete_message(message.chat.id, status_msg.message_id)
        
        # Save to history
        if user_id not in user_chat_history:
            user_chat_history[user_id] = []
        user_chat_history[user_id].append({"role": "user", "content": f"üé• –í–∏–¥–µ–æ: {video_url}"})
        user_chat_history[user_id].append({"role": "assistant", "content": ai_content})
        
        # Send response
        try:
            bot.reply_to(message, ai_content, parse_mode='Markdown')
        except Exception as parse_error:
            logger.warning(f"Markdown parse error: {parse_error}")
            bot.reply_to(message, ai_content)
        
        logger.info(f"[VIDEO] Successfully processed video for user {user_id}")
        
    except requests.exceptions.Timeout:
        logger.error("[VIDEO] Timeout processing video")
        if status_msg:
            bot.edit_message_text("‚ùå —Ç–∞–π–º–∞—É—Ç –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–¥–µ–æ (—Å–ª–∏—à–∫–æ–º –¥–æ–ª–≥–æ)", message.chat.id, status_msg.message_id)
    except Exception as e:
        logger.error(f"[VIDEO] Error processing video: {e}")
        import traceback
        traceback.print_exc()
        if status_msg:
            bot.edit_message_text(f"‚ùå –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–¥–µ–æ: {str(e)}", message.chat.id, status_msg.message_id)
        else:
            bot.reply_to(message, f"‚ùå –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–¥–µ–æ: {str(e)}")

@bot.message_handler(content_types=['video', 'video_note'])
def handle_video_file(message):
    """Handle video file uploads"""
    try:
        bot.reply_to(message, "‚ùå –∑–∞–≥—Ä—É–∑–∫–∞ –≤–∏–¥–µ–æ —Ñ–∞–π–ª–æ–≤ –ø–æ–∫–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è. –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ –≤–∏–¥–µ–æ (TikTok, YouTube, Instagram)")
    except Exception as e:
        logger.error(f"Error in handle_video_file: {e}")

@bot.message_handler(content_types=['voice'])
def handle_voice(message):
    """Handle voice messages with speech recognition"""
    status_msg = None
    temp_input_path = None
    temp_audio_path = None
    
    try:
        voice = message.voice
        status_msg = bot.reply_to(message, "üéôÔ∏è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤—ã–≤–∞—é –≥–æ–ª–æ—Å–æ–≤–æ–µ... [‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 0%")
        
        # Download voice file
        bot.edit_message_text("üéôÔ∏è –ø–æ–ª—É—á–∞—é –≥–æ–ª–æ—Å–æ–≤–æ–µ... [‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 20%", message.chat.id, status_msg.message_id)
        file_info = bot.get_file(voice.file_id)
        downloaded_file = bot.download_file(file_info.file_path)
        
        # Save to temporary file
        temp_input_path = os.path.join(tempfile.gettempdir(), f"{voice.file_unique_id}.ogg")
        with open(temp_input_path, 'wb') as f:
            f.write(downloaded_file)
        
        # Convert to WAV
        bot.edit_message_text("üéôÔ∏è –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É—é –≤ wav... [‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 40%", message.chat.id, status_msg.message_id)
        audio = AudioSegment.from_file(temp_input_path, format="ogg")
        temp_audio_path = temp_input_path.replace(".ogg", ".wav")
        audio.set_frame_rate(16000).set_channels(1).set_sample_width(2).export(temp_audio_path, format="wav")
        
        # Transcribe speech
        bot.edit_message_text("üéôÔ∏è —Ä–∞—Å–ø–æ–∑–Ω–∞—é —Ä–µ—á—å... [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë] 60%", message.chat.id, status_msg.message_id)
        text = ""
        try:
            with sr.AudioFile(temp_audio_path) as source:
                # Adjust for ambient noise
                recognizer.adjust_for_ambient_noise(source, duration=0.5)
                
                # Record the audio
                audio_data = recognizer.record(source)
                
                # Recognize speech using Google Speech Recognition
                text = recognizer.recognize_google(audio_data, language='ru-RU')
                
        except sr.UnknownValueError:
            text = "–Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å"
        except sr.RequestError as e:
            text = f"–æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–∏—Å–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏: {e}"
        except Exception as e:
            text = f"–æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏ —Ä–µ—á–∏: {e}"
        
        # Generate AI response to transcribed text
        bot.edit_message_text("ü§ñ –≥–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç–≤–µ—Ç... [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë] 80%", message.chat.id, status_msg.message_id)
        
        if text and text != "–Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å" and not text.startswith("–æ—à–∏–±–∫–∞"):
            # Generate AI response with user context
            user_id = message.from_user.id
            future = asyncio.run_coroutine_threadsafe(generate_ai_response(text, user_id), asyncio_loop)
            ai_response = future.result(timeout=30)
            
            # Send both transcription and AI response
            bot.edit_message_text("‚úÖ –≥–æ—Ç–æ–≤–æ! [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100%", message.chat.id, status_msg.message_id)
            try:
                bot.send_message(
                    message.chat.id,
                    f"üéôÔ∏è **—Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞:** {text}\n\nü§ñ **–æ—Ç–≤–µ—Ç:** {ai_response}",
                    parse_mode="Markdown"
                )
            except Exception as parse_error:
                # –ï—Å–ª–∏ Markdown –Ω–µ –ø–∞—Ä—Å–∏—Ç—Å—è, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
                logger.warning(f"Markdown parse error in voice handler: {parse_error}")
                bot.send_message(
                    message.chat.id,
                    f"üéôÔ∏è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞: {text}\n\nü§ñ –æ—Ç–≤–µ—Ç: {ai_response}"
                )
        else:
            # Send only transcription if recognition failed
            bot.edit_message_text("‚ö†Ô∏è –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å", message.chat.id, status_msg.message_id)
            bot.send_message(message.chat.id, f"üéôÔ∏è {text}")
        
        # Delete status message
        if status_msg:
            try:
                bot.delete_message(message.chat.id, status_msg.message_id)
            except Exception as del_e:
                logger.warning(f"Failed to delete status message: {del_e}")
        
    except Exception as e:
        logger.error(f"Error in handle_voice: {e}", exc_info=True)
        error_message = f"‚ùå –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ: {str(e)}"
        if status_msg:
            try:
                bot.edit_message_text(error_message, message.chat.id, status_msg.message_id)
            except Exception as edit_e:
                logger.error(f"Failed to edit status message: {edit_e}")
                bot.reply_to(message, error_message)
        else:
            bot.reply_to(message, error_message)
    
    finally:
        # Clean up temporary files
        if temp_input_path and os.path.exists(temp_input_path):
            try:
                os.remove(temp_input_path)
            except Exception as e:
                logger.warning(f"Failed to remove temp input file: {e}")
        if temp_audio_path and os.path.exists(temp_audio_path):
            try:
                os.remove(temp_audio_path)
            except Exception as e:
                logger.warning(f"Failed to remove temp audio file: {e}")

@bot.inline_handler(lambda query: len(query.query) > 0)
def handle_inline_query(inline_query):
    try:
        query_text = inline_query.query.strip()
        
        if not query_text:
            return
        
        results = []
        
        # Regular AI assistant query
        try:
            # Generate AI response with user context for inline mode
            user_id = inline_query.from_user.id
            logger.info(f"Processing inline query: {query_text[:50]}...")
            
            future = asyncio.run_coroutine_threadsafe(generate_ai_response(query_text, user_id, is_inline=True), asyncio_loop)
            response = future.result(timeout=15)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –æ—Ç–≤–µ—Ç –Ω–µ –ø—É—Å—Ç–æ–π –∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –æ—à–∏–±–∫–∏
            if not response or len(response.strip()) < 3:
                logger.warning(f"Empty or too short response: '{response}'")
                response = "–∏–∑–≤–∏–Ω–∏, –Ω–µ —Å–º–æ–≥ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç. –ø–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑."
            elif response.startswith("‚ùå"):
                logger.warning(f"Error response received: {response}")
                # –ï—Å–ª–∏ —ç—Ç–æ –æ—à–∏–±–∫–∞ API, –¥–∞–µ–º –±–æ–ª–µ–µ –ø–æ–Ω—è—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                if "–æ—à–∏–±–∫–∞" in response.lower():
                    response = "–≤—Ä–µ–º–µ–Ω–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞ —Å —Å–µ—Ä–≤–µ—Ä–æ–º. –ø–æ–ø—Ä–æ–±—É–π —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É."
            
            # Create inline result - just the response without extra formatting
            results.append(
                types.InlineQueryResultArticle(
                    id='ai_response',
                    title='ü§ñ –æ—Ç–≤–µ—Ç',
                    description=response[:100] + ('...' if len(response) > 100 else ''),
                    input_message_content=types.InputTextMessageContent(
                        message_text=response
                    )
                )
            )
            
        except asyncio.TimeoutError:
            logger.error("Timeout generating AI response for inline query")
            results.append(
                types.InlineQueryResultArticle(
                    id='ai_timeout',
                    title='‚è±Ô∏è —Ç–∞–π–º–∞—É—Ç',
                    description='—Å–µ—Ä–≤–µ—Ä –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç. –ø–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑.',
                    input_message_content=types.InputTextMessageContent(
                        message_text='‚è±Ô∏è —Å–µ—Ä–≤–µ—Ä –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç. –ø–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑.'
                    )
                )
            )
        except Exception as e:
            logger.error(f"Error generating AI response: {e}")
            results.append(
                types.InlineQueryResultArticle(
                    id='ai_error',
                    title='‚ùå –æ—à–∏–±–∫–∞ ai',
                    description='–Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç. –ø–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑.',
                    input_message_content=types.InputTextMessageContent(
                        message_text='‚ùå –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç. –ø–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑.'
                    )
                )
            )
        
        # Answer inline query - –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if results:
            bot.answer_inline_query(inline_query.id, results, cache_time=1)
        else:
            logger.warning("No results to send for inline query")
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º fallback —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            fallback_result = types.InlineQueryResultArticle(
                id='fallback',
                title='ü§ñ dreamgpt',
                description='–Ω–∞–ø–∏—à–∏ –≤–æ–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞',
                input_message_content=types.InputTextMessageContent(
                    message_text='ü§ñ dreamgpt - –Ω–∞–ø–∏—à–∏ –≤–æ–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞'
                )
            )
            bot.answer_inline_query(inline_query.id, [fallback_result], cache_time=1)
        
    except Exception as e:
        logger.error(f"Error in handle_inline_query: {e}")
        try:
            # Send error result
            error_result = types.InlineQueryResultArticle(
                id='error',
                title='‚ùå –æ—à–∏–±–∫–∞ –±–æ—Ç–∞',
                description='–ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞',
                input_message_content=types.InputTextMessageContent(
                    message_text='‚ùå –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞'
                )
            )
            bot.answer_inline_query(inline_query.id, [error_result], cache_time=1)
        except Exception as answer_error:
            logger.error(f"Failed to answer inline query: {answer_error}")
            # –ï—Å–ª–∏ –¥–∞–∂–µ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–µ –º–æ–∂–µ–º, –ø—Ä–æ—Å—Ç–æ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º

if __name__ == '__main__':
    logger.info("–ó–∞–ø—É—Å–∫ AI –±–æ—Ç–∞ DreamGPT...")
    
    while True:
        try:
            logger.info("–ó–∞–ø—É—Å–∫ polling...")
            bot.polling(non_stop=True, skip_pending=True, timeout=60)
        except KeyboardInterrupt:
            logger.info("–ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º.")
            break
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ polling: {e}")
            logger.info("–ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ 10 —Å–µ–∫—É–Ω–¥...")
            import time
            time.sleep(10)
    
    logger.info("AI –±–æ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω.")
